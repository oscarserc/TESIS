{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMllsxuo+Kh3EDcdvzLvuUv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oscarserc/TESIS/blob/main/PASO_3____Deteccion_de_agentes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**UTILIZACIÓN DE TÉCNICAS DE APRENDIZAJE AUTOMÁTICO PARA LA DETECCIÓN DE LOS NODOS CONFLICTIVOS EN UNA RED SOCIAL**.\n",
        "\n",
        "La base de datos que emplearemos puede llegar a unas 12.000 observaciones. El tamaño crece rápidamente. Por ejemplo 4000 observaciones son aproximadamente 50 MB.\n",
        "\n",
        "· Pruebas iniciales con: 4.000 observaciones\n",
        "\n",
        "· Para ello generamos una 100 **simulaciones**, y guardamos unos 40 **frames** de cada una de ellas\n",
        "\n",
        "· Además como **target** guardamos la matriz con la IDENTIDAD de todos y cada uno de los AGENTES.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ck6WE2qgmKul"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yclIUzOWcSjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ijoWUtiKcSpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El procedimiento que emplearemos se puede resumir en que utilizaremos diversos tipos de arquitectura de Red Neuronal especializadas en visión por computadora. En concreto, aplicaremos técnicas de Segmentación a las imágenes generadas durante la fase de simulación, que nos permiten clasificar todos y cada uno de los píxeles de la imagen una vez entrenada la red para llevar a cabo esta tarea.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://github.com/oscarserc/IMAGENES/blob/main/Input_Output_1a.png?raw=true' width=\"500\"/>\n",
        "<figcaption>fig. 1: Utilizando como <b>input</b>, la simulación de las interacciones emocionales en la Red, pretendemos conseguir que el procesamiento de la Red Neuronal produzca como <b>output</b> la clasificación de todos los nodos de la Red (en la imagen: <b>0</b> (<i>agente emocional</i> ) y <b>1</b> (<i>agente mutante traidor</i> ). </figcaption></center>\n",
        "</figure>\n",
        "\n",
        "<br>\n",
        "\n",
        "Las imágenes para representar la dinámica de la Red Social se guardaron en una base de datos para poder entrenar a la Red Neuronal.\n"
      ],
      "metadata": {
        "id": "DeSAwMEUo2dj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3ot9Dr2qF0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TgqnIlD2qF3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**BASE DE DATOS**: Entrenaremos las distintas arquitecturas neuronales con la base de datos de simulaciones que hemos generado, y cuyo aspecto se puede ver a continuación."
      ],
      "metadata": {
        "id": "F1wDGIWlcnLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://github.com/oscarserc/IMAGENES/blob/main/Matriz_BD_1b.png?raw=true' width=\"950\"/>\n",
        "<figcaption>fig. 2: Fragmento de la base de datos de Simulaciones de la red social que hemos generado.</figcaption></center>\n",
        "</figure>\n"
      ],
      "metadata": {
        "id": "xy5oX0_Qc2m5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la figura de arriba podemos observar un fragmento de las primeras 4000 filas. Las filas aparecen aleatorizadas, tal y como se puede comprobar observando el índice de la columna <b>Simulacion_ID</b> (<i>que representa el número de simulación</i> ). De cada simulación se han guardado 40 transiciones. Su número aparece en la columna <b>Frame</b>.\n",
        "\n",
        "Para empezar utilizamos simulaciones con **AGENTES EMOCIONALES** (0), y **AGENTES MUTANTES TRAIDORES** infiltrados (1) que representan a los acosadores. La identidad de todos los agentes de cada simulación aparece en la columna Target en formato array unidimensional (fácilmente recuperable como una matriz cuadrada).\n",
        "\n",
        "En lo que sigue aparecen las estructuras neuronales que estudiaremos en la fase experimental."
      ],
      "metadata": {
        "id": "UJOp9oiGexop"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DI506iOhmdyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ku6oEvMV0pzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PRUEBA 1**: Utilizaremos una <font color='green'>**RED NEURONAL CONVOLUCIONAL**</font>."
      ],
      "metadata": {
        "id": "Q1K5T8gmcRFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://github.com/oscarserc/IMAGENES/blob/main/CNN_1h2_%20ampliado.png?raw=true' width=\"750\"/>\n",
        "<figcaption>fig. 3: Estructura de la Red Neuronal Convolucional. Generamos 2 máscaras, una para cada clase para hacer la predicción.</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "<br>\n",
        "\n",
        "La imagen de entrada (INPUT) representando el estado emocional de la red está compuesta por los 3 canales RGB, que serán procesados mediante 2 operaciones de convolución consecutivas. La salida está formada por una matriz para cada una de las clases que estamos intentado predecir (en este caso dos). Son matrices del mismo tamaño de la imagen de entrada y cada una contiene la probabilidad de la presencia del tipo de agente en cuestión en cada celda."
      ],
      "metadata": {
        "id": "kYzj5n-tL7mc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xpykoNS6TjqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EubDPNjJTjtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PRUEBA 2**: Utilizaremos una <font color='green'>**RED NEURONAL CONVOLUCIONAL 3D**</font>."
      ],
      "metadata": {
        "id": "zFc8Qe64xyEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://github.com/oscarserc/IMAGENES/blob/main/CNN_3D__4___pruebas_a4__Sementacion2clases.png?raw=true' width=\"950\"/>\n",
        "<figcaption>fig. 4: En esta primera prueba manejamos sólo dos tipos de agentes: <b>Agente EMOCIONAL</b> y <b>Agente MUTANTE TRAIDOR</b>. Por ello el problema se trata de uno de CLASIFICACIÓN BINARIA. Cada pixel ha de ser marcado como perteneciente a una población u otra. La salida de la red son dos matrices de 10x10 (dos por cada frame de la animación) con la probabilidad de pertenencia a cada clase.</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "<br>\n",
        "\n",
        "En este caso el INPUT de la red son lotes de <b>secuencias consecutivas de imágenes</b> de la simulación. Se lleva a cabo el procesamiento mediante 2 convoluciones y la salida es igual al caso anterior."
      ],
      "metadata": {
        "id": "qFd1vecsMkf_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ho3Wg1cAx1qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZN1JbTvUx1tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PRUEBA 3**: Utilizaremos una <font color='green'>**ARQUITECTURA NEURONAL U-Net**</font>. Formada por estructuras <b>encoder</b> y <b>decoder</b>."
      ],
      "metadata": {
        "id": "W4HVyMUKx35v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://github.com/oscarserc/IMAGENES/blob/main/U_Net_2b.png?raw=true' width=\"950\"/>\n",
        "<figcaption>fig. 5: La arquitectura <b>U-Net</b> utiliza la vía inferior para procesar patrones locales en la imagen y la conexión encoder-decoder (que discurre horizontalmente) para detectar patrones más globales y de alto nivel.</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "Al igual que en los casos anteriores el punto de partida son los 3 canales RGB en los que está codificada la situación emocional de la red. La salida es nuevamente la imagen segmentada a través de la generación de matrices para cada uno de los tipos de agentes con los que ha sido entrenada la red neuronal."
      ],
      "metadata": {
        "id": "QoSdKnQMPNkI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8j2MGVByGA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ON286xAcyGD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**PRUEBA 4**: Utilizaremos una <font color='green'>**ARQUITECTURA NEURONAL TRANSFORMER**</font>. En nuestro caso emplearemos sólamente la parte <b>encoder</b>, a la que se añadirá una cabeza de segmentación.\n"
      ],
      "metadata": {
        "id": "kT5OPDIVI7zh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://github.com/oscarserc/IMAGENES/blob/main/Visual_Transformer_1b.png?raw=true' width=\"950\"/>\n",
        "<figcaption>fig. 6: Esquema de la arquitectura Visual Transformer (ViT) <font color='blue'>[Dosovitskiy, A. et al. (2021)]</font>, pero adaptada para segmentar imágenes, y que emplea internamente un Transformer Encoder.</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "<br>\n",
        "\n",
        "En este caso la imagen es troceada antes de entrar en la red neuronal. Nos encontramos ante una arquitectura que procesa secuencias (su origen está en el Procesamiento de Lenguaje Natural). Finalmente se genera una matriz para la segmentación por cada clase que se quiere detectar, y con ellas se genera el output final recomponiendo con estos fragmentos una imagen del mismo tamaño que la origina, en la que cada pixel contiene la identidad del agente que ocupa dicha posición en la Red Social."
      ],
      "metadata": {
        "id": "wrfo1vzKRMJW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x8Jw_VZvJPRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "six6OSzZJPbC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}