{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyON+iS6KufuC7iB+g4QXw1R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oscarserc/TESIS/blob/main/PASO_3e___TRANSFORMERS_En_construccion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#UTILIZACIÓN DE TÉCNICAS DE APRENDIZAJE AUTOMÁTICO PARA LA DETECCIÓN DE LOS PUNTOS DE CONFLICTIVIDAD EN LA RED SOCIAL.\n",
        "\n",
        "La base de datos que emplearemos será de unas 70.000 observaciones. En concreto:\n",
        "\n",
        "· 72.000 observaciones\n",
        "\n",
        "· Para ello generamos una 1800 **simulaciones**, y guardamos unos 40 **frames** de cada una de ellas\n",
        "\n",
        "· Además como **target** guardamos la matriz con la IDENTIDAD de todos y cada uno de los AGENTES.\n",
        "\n"
      ],
      "metadata": {
        "id": "_d-Pbux9LJ7N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g8whJ49ouxRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dgo-MKVHuxUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prueba con los Mecanismos de atención del TRANSFORMER**\n",
        "\n",
        "## Utilización de la librería PyTorch\n",
        "\n",
        "Vamos a construir primero una matriz que simule un embeding. Algunos de los elementos de la secuencia serán más similares que otros entre sí."
      ],
      "metadata": {
        "id": "ibvt8MtXflae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "a = torch.arange(8).reshape(2,4)\n",
        "a\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDCNoY-k9SXE",
        "outputId": "1bdd0e2d-df41-4702-bce3-bb2878274659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 2, 3],\n",
              "        [4, 5, 6, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "b = a.view(2,2,2)\n"
      ],
      "metadata": {
        "id": "6fpu38Es9Sbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "b\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18kleqEiBbnn",
        "outputId": "47efb9c2-744e-442e-991d-2f5bc9740e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 1],\n",
              "         [2, 3]],\n",
              "\n",
              "        [[4, 5],\n",
              "         [6, 7]]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "b[0,:,:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKavAD5iAlEV",
        "outputId": "2a4c377c-bd68-4a48-8fd1-cc90fa0ba2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PsOIRGEyAlIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "a = torch.zeros(3,5)\n",
        "a[0,:] = 1\n",
        "a[1,:] = 2\n",
        "a[2,:] =3\n",
        "a\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1cLSBA8AfZM",
        "outputId": "4636add9-7cd7-4014-9569-bbf7989b3a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1.],\n",
              "        [2., 2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a.reshape(5,3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEE1Jt88AffV",
        "outputId": "2c0c806f-231e-413b-f975-7ed12d4199be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 2.],\n",
              "        [2., 2., 2.],\n",
              "        [2., 3., 3.],\n",
              "        [3., 3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a.transpose(0,1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYjIUSbzA_n7",
        "outputId": "90d2c32d-e0f8-4add-a2f0-9407b559498f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [1., 2., 3.],\n",
              "        [1., 2., 3.],\n",
              "        [1., 2., 3.],\n",
              "        [1., 2., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "b = a.unsqueeze(0)\n",
        "b.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRphob1pA_1l",
        "outputId": "815f360b-abf5-49a1-a65e-20bbc5674243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "b\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl_C5kCMBjfr",
        "outputId": "33e8bb56-db1a-4964-c886-778cd1475c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1., 1.],\n",
              "         [2., 2., 2., 2., 2.],\n",
              "         [3., 3., 3., 3., 3.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "c = b.permute(2,0,1)\n",
        "c\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCBrU4JbA_41",
        "outputId": "e7906f66-222e-4100-acf2-9219dfe8c55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2., 3.]],\n",
              "\n",
              "        [[1., 2., 3.]],\n",
              "\n",
              "        [[1., 2., 3.]],\n",
              "\n",
              "        [[1., 2., 3.]],\n",
              "\n",
              "        [[1., 2., 3.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "c.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRyKhDYoBcQg",
        "outputId": "799090d8-de61-4b59-901b-5b80484008cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11c44JUwBcTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mecanismos de atención**\n",
        "\n",
        "Vamos a construir primero una matriz que simule un embeding. Algunos de los elementos de la secuencia serán más similares que otros entre sí."
      ],
      "metadata": {
        "id": "xx9UNRAafeal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "# Supongamos:\n",
        "# · Longitud de la secuencia:  T = 5\n",
        "# · Dimensión del embedding :  D = 10\n",
        "T = 5\n",
        "D = 12\n",
        "x = torch.zeros(5,12)\n",
        "x[0,:] = 1\n",
        "x[1,:] = 2\n",
        "x[2,:] = 3\n",
        "x[3,:] = 2\n",
        "x[4,:] = 6\n",
        "x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pac9sqldUJq1",
        "outputId": "cccb34e5-ef65-4c6e-bcf1-237bccf446e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "        [6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_embd  = D\n",
        "n_heads = 2\n",
        "\n",
        "key   = torch.nn.Linear(n_embd, n_embd//n_heads)\n",
        "query = torch.nn.Linear(n_embd, n_embd//n_heads)\n",
        "value = torch.nn.Linear(n_embd, n_embd//n_heads)\n",
        "key(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-gIwZd2U35V",
        "outputId": "d2c8b090-a623-43d4-9219-835fe8f4ae2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5899, -0.4960, -0.9899, -0.2596, -0.6884, -0.2277],\n",
              "        [-1.1424, -0.9016, -1.7010, -0.7512, -1.1408, -0.6714],\n",
              "        [-1.6949, -1.3073, -2.4122, -1.2428, -1.5931, -1.1152],\n",
              "        [-1.1424, -0.9016, -1.7010, -0.7512, -1.1408, -0.6714],\n",
              "        [-3.3524, -2.5243, -4.5456, -2.7176, -2.9502, -2.4464]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_batch = torch.unsqueeze(x, dim=0)\n",
        "x_batch.shape\n",
        "\n",
        "dim_qkv = D // n_heads\n",
        "\n",
        "#B, T, dim_Embd = x.size()\n",
        "x.view(T, dim_qkv, n_heads)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMvsPCX8U4IL",
        "outputId": "4e81fbde-c35b-4fb5-8fde-47d92764868b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.],\n",
              "         [1., 1.]],\n",
              "\n",
              "        [[2., 2.],\n",
              "         [2., 2.],\n",
              "         [2., 2.],\n",
              "         [2., 2.],\n",
              "         [2., 2.],\n",
              "         [2., 2.]],\n",
              "\n",
              "        [[3., 3.],\n",
              "         [3., 3.],\n",
              "         [3., 3.],\n",
              "         [3., 3.],\n",
              "         [3., 3.],\n",
              "         [3., 3.]],\n",
              "\n",
              "        [[2., 2.],\n",
              "         [2., 2.],\n",
              "         [2., 2.],\n",
              "         [2., 2.],\n",
              "         [2., 2.],\n",
              "         [2., 2.]],\n",
              "\n",
              "        [[6., 6.],\n",
              "         [6., 6.],\n",
              "         [6., 6.],\n",
              "         [6., 6.],\n",
              "         [6., 6.],\n",
              "         [6., 6.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CONTENIDO de cada una de las CABEZAS\n",
        "x.view(T, dim_qkv, n_heads).transpose(0,2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q8h-e8TU4MH",
        "outputId": "f9781cec-7a77-4235-a999-86075d89f63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.]],\n",
              "\n",
              "        [[1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DETALLES**"
      ],
      "metadata": {
        "id": "D78aBPmHFpi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "\n",
        "# Supongamos:\n",
        "# · Longitud de la secuencia:  T = 5 (5 tokens)\n",
        "# · Dimensión del embedding :  D = 12\n",
        "\n",
        "T = 5\n",
        "D = 12\n",
        "\n",
        "x = torch.zeros(5,D)\n",
        "x[0,:] = 1\n",
        "x[1,:] = 2\n",
        "x[2,:] = 3\n",
        "x[3,:] = 2\n",
        "x[4,:] = 6\n",
        "x\n",
        "\n",
        "# SUPONEMOS QUE ES LA SALIDA YA DE LA RED NEURONAL\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b91YHK1vFpu-",
        "outputId": "31bb30c0-a263-44d1-d670-2e1532163b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "        [6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Supongamos que tenemos 4 cabezas.\n",
        "# El embedding (D=12) lo representamos como una matriz\n",
        "# Usaremos h = 4 cabezas\n",
        "\n",
        "# Entoces tenemos que cada TOKEN (T=5) quedará representado\n",
        "# como una matriz. El EMBEDDING se ha fragmentado para dividir\n",
        "# entre varias unidades de procesamiento que puedan centrarse\n",
        "# en aspectos y matices particulares del INPUT.\n",
        "\n",
        "# D = 12  y tomamos h = 4 cabezas\n",
        "# luego cada una va a trabajar con una pequeña fracción del\n",
        "# espacio. en concreto: d_h = 3.\n",
        "h = 4\n",
        "x.view(5,3,h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_EUqvw4Fpzb",
        "outputId": "d23b6aa8-0300-4eb2-a76b-28629409c474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]],\n",
              "\n",
              "        [[2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2.]],\n",
              "\n",
              "        [[3., 3., 3., 3.],\n",
              "         [3., 3., 3., 3.],\n",
              "         [3., 3., 3., 3.]],\n",
              "\n",
              "        [[2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2.]],\n",
              "\n",
              "        [[6., 6., 6., 6.],\n",
              "         [6., 6., 6., 6.],\n",
              "         [6., 6., 6., 6.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x.view(5,3,h).transpose(0,2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhesay9NFp23",
        "outputId": "013ca410-a37f-4846-e551-95c69623c7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.]],\n",
              "\n",
              "        [[1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.]],\n",
              "\n",
              "        [[1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.]],\n",
              "\n",
              "        [[1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# CABEZA h = 1     1/4 (indice = 0)\n",
        "# ============\n",
        "\n",
        "# Embedding ------> d = 12/4 = 3 (La parte que le\n",
        "#                                 haya tocado de\n",
        "#                                 los D=12)\n",
        "# Tokens ---------> T = 5\n",
        "x.view(5,3,h).transpose(0,2)[0,:,:]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVpD_Nf1Fp5o",
        "outputId": "59d2d3d6-8eeb-4a6b-dcdd-beb7db8272e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3., 2., 6.],\n",
              "        [1., 2., 3., 2., 6.],\n",
              "        [1., 2., 3., 2., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y = x.view(5,3,h).transpose(0,2)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHXLaBc0cAoq",
        "outputId": "8deaa8f1-49af-4544-f3ab-532850746942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.]],\n",
              "\n",
              "        [[1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.]],\n",
              "\n",
              "        [[1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.]],\n",
              "\n",
              "        [[1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.],\n",
              "         [1., 2., 3., 2., 6.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y.transpose(0,2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5j_Ifqxe_ir",
        "outputId": "082a21e1-fda0-43c6-ec55-3cac8012b08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]],\n",
              "\n",
              "        [[2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2.]],\n",
              "\n",
              "        [[3., 3., 3., 3.],\n",
              "         [3., 3., 3., 3.],\n",
              "         [3., 3., 3., 3.]],\n",
              "\n",
              "        [[2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2.]],\n",
              "\n",
              "        [[6., 6., 6., 6.],\n",
              "         [6., 6., 6., 6.],\n",
              "         [6., 6., 6., 6.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ver si hay ERROR\n",
        "# ----------------\n",
        "\n",
        "# En el de SENSIO aparece (1,2), no el (1,3) que era\n",
        "# el que había cambiado previamente\n",
        "y.transpose(0,2).contiguous().view(5,3*h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRvvso1ecAwl",
        "outputId": "3c048237-f7fd-4bf4-88f6-5a3f0a3308c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "        [2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "        [6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eso5xz-kcAz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wBFkzX3wcA3g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}